# -*- coding: utf-8 -*-
"""Customer Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19dOtNzDKhoaINKToJQD9pDT7s76Vm9lF
"""

#import required Libraries for clustering
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import sklearn
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

retail = pd.read_csv('OnlineRetail.csv', sep=",",encoding="ISO-8859-1",header=0)

retail.head()

#shape of DF
retail.shape

# df info
retail.info()

"""**Data Cleaning**"""

# Calculating the missing values % contribution in DF

df_null = round(100*(retail.isnull().sum())/len(retail), 2)
df_null

# droping rows having missing values
retail = retail.dropna()
retail.shape

# changing the datatype od customer ID
retail['CustomerID'] = retail['CustomerID'].astype(str)

# New Attribute : Monetory

retail['Amount'] = retail['Quantity']*retail['UnitPrice']
rfm_m = retail.groupby('CustomerID')['Amount'].sum()
rfm_m = rfm_m.reset_index()
rfm_m.head()

# New Attribute : Frequency

rfm_f = retail.groupby('CustomerID')['InvoiceNo'].count()
rfm_f = rfm_f.reset_index()
rfm_f.column = ['CustomerID', 'Frrequency']
rfm_f.head()

# merging the Two DFs
rfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')
rfm.head()

# New Attribut : Recency

# Convert to datetime to proper datatype
retail['InvoiceDate'] = pd.to_datetime(retail['InvoiceDate'],infer_datetime_format=True)
retail['InvoiceDate']

# campute the maximum date to know the last transaction date
max_date = max(retail['InvoiceDate'])
max_date

# calculate the difference
retail['Diff'] = max_date - retail['InvoiceDate']
retail.head()

# caompute recency of customer
rfm_p = retail.groupby('CustomerID')['Diff'].min()
rfm_p = rfm_p.reset_index()
rfm_p.head()

#Extract Number of days only (Round Figure)
rfm_p['Diff'] = rfm_p['Diff'].dt.days
rfm_p.head()

# Merge the dataframes to get the final RFM dataframe

# Re-create rfm by merging monetary and frequency data
rfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')

# Merge with recency data
rfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')

# Rename the columns to final RFM attributes
rfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']
rfm.head()

# outlier Analysis of Amount frequency and Recency

attributes = ['Amount','Frequency','Recency']
plt.rcParams['figure.figsize'] = [10,8]
sns.boxplot(data = rfm[attributes], orient="v",whis=1.5,saturation=1,width=0.7)
plt.title('Outliers Variable Distribution', fontsize = 14, fontweight = 'bold')
plt.ylabel('Variable Ranges', fontsize = 12, fontweight = 'bold')
plt.xlabel('Variables', fontsize = 12, fontweight = 'bold')
plt.show()

# removing outliers for Amount
Q1 = rfm.Amount.quantile(0.05)
Q3 = rfm.Amount.quantile(0.95)
IQR = Q3 - Q1
rfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]

# removing outliers for Recency
Q1 = rfm.Recency.quantile(0.05)
Q3 = rfm.Recency.quantile(0.95)
IQR = Q3 - Q1
rfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]

# removing outliers for Frequency
Q1 = rfm.Frequency.quantile(0.05)
Q3 = rfm.Frequency.quantile(0.95)
IQR = Q3 - Q1
rfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]

"""**Scaling Features**"""

scaler = StandardScaler()

rfm_df = rfm[['Amount', 'Frequency', 'Recency']]

#fit transform
rfm_df = scaler.fit_transform(rfm_df)
rfm_df.shape

rfm_df = pd.DataFrame(rfm_df)
rfm_df.columns = ['Amount', 'Frequency', 'Recency']
rfm_df.head()

"""**Model Building**"""

# K-Means with some Arbitrary

kmeans =KMeans(n_clusters=4, max_iter=50)
kmeans.fit(rfm_df)

kmeans.labels_

set(kmeans.labels_)

"""**Elbow Curve to get the right number of Clusters**"""

std=[]
range_n_clusters = [2,3,4,5,6,7,8]
for num_clusters in range_n_clusters:
  kmeans = KMeans(n_clusters=num_clusters, max_iter=50)
  kmeans.fit(rfm_df)
  std.append(kmeans.inertia_)
plt.plot(std)

# final Model with n = 3
kmeans = KMeans(n_clusters=3, max_iter=300)
kmeans.fit(rfm_df)

# Define filename for pickle file
import pickle
filename = 'kmeans_model.pkl'

# open file in write mode
with open('kmeans_saved_model','wb') as file:
  pickle.dump(kmeans, file)

file.close()

pickle.dump(kmeans, open('kmean_model.pkl','wb'))

